# Обработка естественных языков

## Вопросы для самоподготовки к занятию

 - Из каких этапов состоит обработка текстов?
 - Что такое токенизация и зачем это нужно?
 - Что такое стемминг и лемматизация? В чем их отличия?
 - Что такое n-граммы?
 - Что такое матрица term-document? Зачем она нужна? Как строится? Причем тут bag-of-words?
 - Что такое tf-idf? Зачем нужен?
 - Что такое word embeddings?
 - Как работает word2vec? Чем отличается CBOW от skip-gram и что это такое?

## Материалы для самоподготовки

1. Предобработка данных в NLP
 - https://en.wikipedia.org/wiki/Lemmatisation
 - https://en.wikipedia.org/wiki/Stemming
 - https://en.wikipedia.org/wiki/Tokenization_(lexical_analysis)
 - https://en.wikipedia.org/wiki/N-gram

2. Извлечение признаков из текстовых данных
 - https://en.wikipedia.org/wiki/Document-term_matrix
 - http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction

3. Векторное представление слов
 - http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
 - https://en.wikipedia.org/wiki/Word2vec
 - http://nlpx.net/archives/179

## Задание для подготовки к занятию

Пройти [туториал](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html) по работе с текстовыми данными. Упражнения выполнять не нужно.
